services:
  translationteacherwasm:
    image: translationteacherwasm
    build:
      context: .
      dockerfile: TranslationTeacherWasm/Dockerfile
      
  parlertts-api:
    build:
      context: .
      dockerfile: ParlerTTSAPI/Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./app_models/hfcache:/cache/huggingface
      - ./app_models/ggufs:/models

  translation-llamacpp:
    image: ghcr.io/ggml-org/llama.cpp:server
    runtime: nvidia
    pull_policy: always
    init: true
    ipc: host
    ports:
      - "8081:8080"
    volumes:
      - ./app_models/ggufs:/models
    command: |
      --model /models/Hunyuan-MT-Chimera-7B.Q4_K_M.gguf
      --top-k 20
      --top-p 0.6
      --repeat-penalty 1.05
      --temp 0.7
      --n-gpu-layers 0

  assistant-llamacpp:
    image: ghcr.io/ggml-org/llama.cpp:server
    runtime: nvidia
    pull_policy: always
    init: true
    ipc: host
    ports:
      - "8082:8080"
    volumes:
      - ./app_models/ggufs:/models
    command: |
      --model /models/Qwen3-4B-UD-Q4_K_XL.gguf
      --top-k 20
      --top-p 0.8
      --min-p 0
      --temp 0.7
      --n-gpu-layers 0
      --chat_template_kwargs "{\"enable_thinking\":false}" 
      
  
  download-models:
    image: curlimages/curl:latest
    volumes:
      - ./app_models/ggufs:/models
    command: |
      sh -c "
        curl --skip-existing -L -o /models/Qwen3-4B-UD-Q4_K_XL.gguf https://huggingface.co/unsloth/Qwen3-4B-GGUF/resolve/main/Qwen3-4B-UD-Q4_K_XL.gguf &&
        curl --skip-existing -L -o /models/Hunyuan-MT-Chimera-7B.Q4_K_M.gguf https://huggingface.co/mradermacher/Hunyuan-MT-Chimera-7B-GGUF/resolve/main/Hunyuan-MT-Chimera-7B.Q4_K_M.gguf
      "
    user: "0:0"
  
  asr-service:
    image: onerahmet/openai-whisper-asr-webservice:latest
    volumes:
      - ./app_models/hfcache:/root/.cache/
    expose:
      - 9000
    environment:
      - ASR_ENGINE=faster_whisper
      - ASR_MODEL=large-v3-turbo
    networks:
      - asr-net

  nginx-asr:
    image: nginx:alpine
    depends_on:
      - asr-service
    ports:
      - "9000:9000"
    configs:
      - source: nginx_config_asr
        target: /etc/nginx/conf.d/default.conf
    restart: unless-stopped
    networks:
      - asr-net

networks:
  asr-net:

configs:
  nginx_config_asr:
    content: |
      server {
        listen 9000;
        server_name localhost;

        location / {
          proxy_pass http://asr-service:9000;
          proxy_set_header Host $$host;
          proxy_set_header X-Real-IP $$remote_addr;
          proxy_set_header X-Forwarded-For $$proxy_add_x_forwarded_for;
          proxy_set_header X-Forwarded-Proto $$scheme;
      
          # WebSocket support
          proxy_http_version 1.1;
          proxy_set_header Upgrade $$http_upgrade;
          proxy_set_header Connection "upgrade";
      
          # Fix Streaming
          proxy_buffering off;
      
          # Allow all origins for CORS
          add_header Access-Control-Allow-Origin "*" always;
        
          # Allow specific headers
          add_header Access-Control-Allow-Headers "Origin, X-Requested-With, Content-Type, Accept, Authorization" always;
        
          # Allow specific methods
          add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS" always;
        
          # Handle preflight requests
          if ($$request_method = 'OPTIONS') {
              add_header Access-Control-Allow-Origin "*";
              add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS";
              add_header Access-Control-Allow-Headers "Origin, X-Requested-With, Content-Type, Accept, Authorization";
              add_header Access-Control-Max-Age 86400;
              add_header Content-Length 0;
              add_header Content-Type text/plain;
              return 204;
          }
        }
      }